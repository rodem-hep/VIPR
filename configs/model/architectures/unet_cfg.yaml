_target_: tools.convolutions.conv_nets.UNet
# _convert_: object

device: ${device}

#UNet
embedding_dims : 64
ctxt_dims: 0
input_shape: [1, 64, 64]
channels : [32, 32, 64, 64, 128, 128]
block_depth : 2
min_size: 2
dropout: 0.1
use_gate: true
img_enc: 1 # super-res = 2 else 1

# sub-modules
#FiLM
film_config:
  n_neurons: 64
  n_layers: 8
  activation_str:  leaky_relu
  batchnorm: true
  device: ${device}

# self attention between images
self_attention_cfg:
  attn_below: 16  
  device: ${device}
  attn_heads: 16
  trainable_pe: true
  pos_encode_kwargs: null

# cross attention as gates to residual connection
cross_attention_cfg:
  attn_below: 16
  device: ${device}
  attn_heads: 16
  trainable_pe: true
  pos_encode_kwargs: null
