# _target_: src.datamodules.images.ImageDataModule
_convert_: object

train_set:
  # _target_: torchvision.datasets.FashionMNIST
  # _target_: torchvision.datasets.CIFAR10
  _target_: torchvision.datasets.ImageFolder
  # _partial_: True
  # _partial_: True
  # root: ${path}/test_data/
  root: /srv/beegfs/scratch/groups/rodem/datasets/afhq_v2/train/
  # train: True
  # download: True
  transform:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.Resize
        size: 100
      - _target_: torchvision.transforms.RandomHorizontalFlip
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 64
        scale: [0.4,1]
        ratio: [0.9, 1.1]
      - _target_: torchvision.transforms.ToTensor



# test_set:
#   _target_: ..train_set._target_
#   _partial_: True
#   root: ${paths.data_dir}
#   train: False
#   download: ..train_set.download
#   transform:
#     _target_: torchvision.transforms.Compose
#     transforms:
#       - _target_: torchvision.transforms.PILToTensor
#       - _target_: torchvision.transforms.ConvertImageDtype
#         # dtype:
#         #   _target_: mattstools.mattstools.torch_utils.dtype_lookup
#         #   dtype: float

loader_cfg:
  _target_: torch.utils.data.DataLoader
  _partial_: True
  pin_memory: true
  batch_size: 64
  num_workers:
    _target_: torch.get_num_threads
  drop_last: True
  shuffle: True